{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 5 - Neural networks and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion-MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Download Fashion-MNIST repository/data\n",
    "!rm -rf fashion-mnist/\n",
    "!git clone https://github.com/zalandoresearch/fashion-mnist.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip fashion-mnist/data/fashion/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv fashion-mnist/data/fashion/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function - convertion of binary input to .csv\n",
    "def convertbinMNIST(img, label, output, n):\n",
    "    fimg = open(img, \"rb\")\n",
    "    fout = open(output, \"w\")\n",
    "    flabel = open(label, \"rb\")\n",
    "    \n",
    "    #Get rid of headers\n",
    "    fimg.read(16)\n",
    "    flabel.read(8)\n",
    "    mod = n/10\n",
    "    print(\"Progress: \", end='')\n",
    "    \n",
    "    for i in range(n):\n",
    "        image = [ord(flabel.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(fimg.read(1)))\n",
    "        fout.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "        if i%mod==0:\n",
    "            print(str(int(i/n*100))+\"% \", end='')\n",
    "    print('')\n",
    "    fout.close()\n",
    "    fout.close()\n",
    "    flabel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Converting train and test data to csv\n",
    "convertbinMNIST(\"train-images-idx3-ubyte\", \"train-labels-idx1-ubyte\",\n",
    "        \"fmnist_train.csv\", 60000)\n",
    "convertbinMNIST(\"t10k-images-idx3-ubyte\", \"t10k-labels-idx1-ubyte\",\n",
    "        \"fmnist_test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc fmnist_test.csv\n",
    "!wc fmnist_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "import plotly.graph_objs as go\n",
    "from plotly import subplots\n",
    "from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "IMG_ROWS = 28\n",
    "IMG_COLS = 28\n",
    "CLASSES = 10\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 2020\n",
    "NO_EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train and test data\n",
    "train_data = pd.read_csv(\"fmnist_train.csv\",header=None)\n",
    "test_data = pd.read_csv(\"fmnist_test.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dimensions check\n",
    "print(\"Fashion MNIST train -  rows:\",train_data.shape[0],\" columns:\", train_data.shape[1])\n",
    "print(\"Fashion MNIST test -  rows:\",test_data.shape[0],\" columns:\", test_data.shape[1])\n",
    "#Data loaded properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 10 different classes of images:**\n",
    "\n",
    "* **0**: **T-shirt/top**;   \n",
    "* **1**: **Trouser**;   \n",
    "* **2**: **Pullover**;   \n",
    "* **3**: **Dress**;\n",
    "* **4**: **Coat**;\n",
    "* **5**: **Sandal**;\n",
    "* **6**: **Shirt**;\n",
    "* **7**: **Sneaker**;\n",
    "* **8**: **Bag**;\n",
    "* **9**: **Ankle boot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check labels distribution in training set\n",
    "train_data[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check labels distribution in test set\n",
    "test_data[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function - preparing data for DL model\n",
    "def data_preproc(inp):\n",
    "    out_y = keras.utils.to_categorical(inp[0], CLASSES)\n",
    "    num_images = inp.shape[0]\n",
    "    x_as_array = inp.values[:,1:]\n",
    "    #Reshaping\n",
    "    x_shaped = x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n",
    "    #Scaling\n",
    "    out_x = x_shaped / 255\n",
    "    return out_x, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preproc(train_data)\n",
    "X_test, y_test = data_preproc(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sequential model with Keras\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(CLASSES, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model = model.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=NO_EPOCHS,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#Model achieved 90.8% accuracy on test set\n",
    "#This is looking quite good compared to results on https://github.com/zalandoresearch/fashion-mnist\n",
    "#and considering only 20 epochs were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions - plotting model learning history\n",
    "def create_trace(x,y,ylabel,color):\n",
    "        trace = go.Scatter(\n",
    "            x = x,y = y,\n",
    "            name=ylabel,\n",
    "            marker=dict(color=color),\n",
    "            mode = \"markers+lines\",\n",
    "            text=x\n",
    "        )\n",
    "        return trace\n",
    "    \n",
    "def plot_accuracy_and_loss(train_model):\n",
    "    hist = train_model.history\n",
    "    acc = hist['accuracy']\n",
    "    val_acc = hist['val_accuracy']\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    epochs = list(range(1,len(acc)+1))\n",
    "    \n",
    "    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n",
    "    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n",
    "    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n",
    "    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n",
    "   \n",
    "    fig = subplots.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n",
    "                                                             'Training and validation loss'))\n",
    "    fig.append_trace(trace_ta,1,1)\n",
    "    fig.append_trace(trace_va,1,1)\n",
    "    fig.append_trace(trace_tl,1,2)\n",
    "    fig.append_trace(trace_vl,1,2)\n",
    "    fig['layout']['xaxis'].update(title = 'Epoch')\n",
    "    fig['layout']['xaxis2'].update(title = 'Epoch')\n",
    "    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n",
    "    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n",
    "\n",
    "    \n",
    "    iplot(fig, filename='accuracy-loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_accuracy_and_loss(train_model)\n",
    "#Accuracy and loss looks similar for both training and validation set - overfitting is addressed with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking fit metrics across all classes\n",
    "predicted_classes = model.predict_classes(X_test)\n",
    "y_true = test_data.iloc[:, 0]\n",
    "labels = {0 : \"T-shirt/top\", 1: \"Trousers\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "          5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle Boot\"}\n",
    "target_names = [\"Class {} ({}) :\".format(i,labels[i]) for i in range(CLASSES)]\n",
    "print(classification_report(y_true, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As f1-score combine both precision and recall let's focus on analyzing that metric.\n",
    "By looking on f1-score we can see that some classes were predicted better than other.\n",
    "1. Very well predicted classes (f1 >= 0.9):\n",
    "    * 1-Trousers\n",
    "    * 3-Dress\n",
    "    * 5-Sandal\n",
    "    * 7-Sneaker\n",
    "    * 8-Bag\n",
    "    * 9-Ankle Boot\n",
    "2. Well predicted classes (0.8 =< f1 < 0.9):\n",
    "    * 0-T-shirt\n",
    "    * 2-Pullover\n",
    "    * 4-Coat\n",
    "3. Poorly predicted classes (f1 < 0.8):\n",
    "    * 6-Shirt\n",
    "\n",
    "Shirt is similar to T-shirt, so model may have problem with distingushing those two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model for deployment\n",
    "model.save('FMNIST_Model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment proposal\n",
    "Saved Keras model can be incorporated into application and deployed for end users. For scalable deployment using one of the cloud providers e.g. Google Cloud Platform is one of reasonable optiom. Cloud solutions for app deployment are usually managed and can be scaled automatically based on set metric (CPU usage, requests per second). \n",
    "\n",
    "### App design\n",
    "\n",
    "To expose model we can develop Flask app for developer-based approach (binary input). App files can be found in _keras-app_ folder:\n",
    "* **Dockerfile** - docker definition file to containerize the app\n",
    "* **requirements.txt** - Python dependencies to be loaded in Docker container\n",
    "* **app.py** - Flask app that loads built keras model and wait for binary input on _localhost:5000/predict_ endpoint\n",
    "* **FMNIST_Model.h5** - saved keras model for Fashion-MNIST classification\n",
    "* **example_input** - binary file with one image to classify\n",
    "\n",
    "### Local deployment (for development and validation)\n",
    "I assume Docker is installed locally and it's running.\n",
    "\n",
    "While in keras-app folder, we build Docker image, run container and validate if app is running using:\n",
    "```sh\n",
    "docker build -t keras-app:latest .\n",
    "docker run -d -p 5000:5000 keras-app\n",
    "docker ps -a\n",
    "```\n",
    "Below example request to the deployed app\n",
    "```sh\n",
    "curl -X POST -F image=@example_input 'http://localhost:5000/predict'\n",
    "```\n",
    "We should get JSON response:\n",
    "```json\n",
    "{\n",
    "  \"predictions\": [\n",
    "    {\n",
    "      \"label\": 0,\n",
    "      \"probability\": 0.9999948740005493\n",
    "    },\n",
    "    {\n",
    "      \"label\": 1,\n",
    "      \"probability\": 1.7362290262185748e-13\n",
    "    },\n",
    "    {\n",
    "      \"label\": 2,\n",
    "      \"probability\": 1.8749882428892306e-06\n",
    "    },\n",
    "    {\n",
    "      \"label\": 3,\n",
    "      \"probability\": 1.6042036588004294e-09\n",
    "    },\n",
    "    {\n",
    "      \"label\": 4,\n",
    "      \"probability\": 8.0264128676788e-11\n",
    "    },\n",
    "    {\n",
    "      \"label\": 5,\n",
    "      \"probability\": 9.621579596759606e-18\n",
    "    },\n",
    "    {\n",
    "      \"label\": 6,\n",
    "      \"probability\": 3.266337898821803e-06\n",
    "    },\n",
    "    {\n",
    "      \"label\": 7,\n",
    "      \"probability\": 5.098662132007302e-21\n",
    "    },\n",
    "    {\n",
    "      \"label\": 8,\n",
    "      \"probability\": 4.3966014856566815e-11\n",
    "    },\n",
    "    {\n",
    "      \"label\": 9,\n",
    "      \"probability\": 1.5432945262057027e-17\n",
    "    }\n",
    "  ],\n",
    "  \"success\": true\n",
    "}\n",
    "```\n",
    "\n",
    "### GKE deployment\n",
    "Launch Google Cloud Shell in GCP Console and copy app files (preferably from private git repo)\n",
    "```sh\n",
    "git clone https://github.com/<some_user>/FMNIST-App)\n",
    "cd FMNIST-App\n",
    "```\n",
    "Build Docker image with proper tag for Google Container Registry\n",
    "```sh\n",
    "docker build -t gcr.io/${PROJECT_ID}/FMNIST-app:v1 .\n",
    "```\n",
    "Push image to GCR (I assume shell docker is authenticated in GCR)\n",
    "```sh\n",
    "docker push gcr.io/${PROJECT_ID}/FMNIST-app:v1\n",
    "```\n",
    "Create cluster on GKE\n",
    "```sh\n",
    "gcloud container clusters create FMNIST-cluster --num-nodes=2\n",
    "```\n",
    "Deploy our app on GKE\n",
    "```sh\n",
    "kubectl create deployment FMNIST-web --image=gcr.io/${PROJECT_ID}/FMNIST-app:v1\n",
    "```\n",
    "Expose deployment to internet with Load Balancer\n",
    "```sh\n",
    "kubectl expose deployment FMNIST-web --type=LoadBalancer --port 80 --target-port 5000\n",
    "```\n",
    "We can validate and check availability of the service by running\n",
    "```sh\n",
    "kubectl get pods #Check running pods\n",
    "kubectl get deployment FMNIST-web #Check deployment status\n",
    "kubectl get service #Check LoadBalancer status and external IP\n",
    "#Run on local machine\n",
    "curl -X POST -F image=@example_input http://<EXTERNAL_LB_IP>/predict\n",
    "```\n",
    "To add autoscaling based on CPU utilization we can call\n",
    "```sh\n",
    "kubectl autoscale deployment FNIST-web --cpu-percent=80 --min=1 --max=10\n",
    "```\n",
    "To check information about launched Horizontal Pod Autoscaler (HPA) we can call\n",
    "```sh\n",
    "kubectl get hpa\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
